import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import pipeline
import torch
import time
import os
import re

st.set_page_config(page_title="Humor Topic Classifier", layout="wide", page_icon="ğŸ˜‚")

# ==========================================
# âœ¨ STYLES
# ==========================================
st.markdown("""
<style>
h1 { text-align:center; font-weight:900; font-size:32px; color:#00ADB5; }
footer, header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1>ğŸ˜‚ Humor Topic Classifier</h1>", unsafe_allow_html=True)

# ==========================================
# ğŸ“‚ CARGA DE ARCHIVO
# ==========================================
uploaded_file = st.file_uploader("ğŸ“‚ Sube tu archivo CSV/TSV del Task-A", type=["csv","tsv"])

if uploaded_file:

    df = pd.read_csv(uploaded_file, sep=None, engine="python")
    st.subheader("ğŸ“Š Vista previa de los datos")
    st.dataframe(df.head())

    # ==========================================
    # ğŸ” TEXTO USABLE
    # ==========================================
    def build_text(row):
        if "headline" in df.columns and isinstance(row["headline"], str) and row["headline"] != "-":
            return row["headline"].strip()
        if "word1" in df.columns and "word2" in df.columns:
            return f"{str(row['word1'])} {str(row['word2'])}".strip()
        return ""

    df["text_clean"] = df.apply(build_text, axis=1)

    # ==========================================
    # ğŸ§  MODELO ZERO-SHOT (TEMAS)
    # ==========================================
    st.subheader("ğŸ§  Cargando modelo Zero-Shot BERTâ€¦")
    classifier = pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli",
        device=0 if torch.cuda.is_available() else -1
    )
    st.success("Modelo de temas cargado âœ”")

    topics_list = [
        "politics","celebrities","technology","animals","food",
        "sports","sex","crime","religion","health",
        "work","money","education","family","environment",
        "science","music","movies","internet","military"
    ]

    # ==========================================
    # ğŸ¤£ GENERADOR DE CHISTES (GPT-2)
    # ==========================================
    st.subheader("ğŸ­ Cargando generador de chistesâ€¦")
    joke_gen = pipeline(
        "text-generation",
        model="gpt2",
        pad_token_id=50256,
        device=0 if torch.cuda.is_available() else -1
    )
    st.success("Listo para generar chistes ğŸ˜‚")

    def clean_joke(j):
        j = re.sub(r"\s+", " ", j)
        return j[:140]

    def generate_joke(txt, topic):
        prompt = f"Write a short funny joke about {topic}: {txt}. Joke:"
        out = joke_gen(prompt, max_length=60, temperature=0.95, num_return_sequences=1)
        joke = out[0]["generated_text"].split("Joke:")[-1]
        return clean_joke(joke)

    texts = df["text_clean"].tolist()
    total = len(texts)
    batch_size = 16  # mÃ¡s pequeÃ±o para ir mÃ¡s fluido

    topics, scores, jokes = [], [], []

    progress_bar = st.progress(0)
    status = st.empty()
    logs = st.container()
    start = time.time()

    output_file = "progress_partial.csv"

    # ==========================================
    # ğŸš€ CLASIFICAR + GENERAR CHISTES
    # ==========================================
    st.subheader(f"ğŸ”„ Clasificando {total} textos y generando chistesâ€¦")

    try:
        for i in range(0, total, batch_size):
            batch_texts = texts[i:i+batch_size]

            # ---- clasificaciÃ³n de temas
            results = classifier(
                batch_texts,
                topics_list,
                hypothesis_template="This is about {}."
            )

            for r in results:
                topics.append(r["labels"][0])
                scores.append(float(r["scores"][0]))

            # ---- generaciÃ³n de chistes (uno por texto del batch)
            for idx, txt in enumerate(batch_texts):
                jokes.append(generate_joke(txt, topics[i+idx]))

            # Guardar progreso parcial en el DataFrame
            df.loc[:len(topics)-1, "topic"] = topics
            df.loc[:len(scores)-1, "score"] = scores
            df.loc[:len(jokes)-1, "joke"] = jokes

            df.to_csv(output_file, index=False)

            # Progreso
            prog = (i + batch_size) / total
            elapsed = time.time() - start
            eta = (elapsed/prog) - elapsed if prog > 0 else 0

            progress_bar.progress(min(prog, 1.0))
            status.info(f"âœ” {min(i+batch_size,total)}/{total} â€¢ {prog*100:.1f}% â€¢ â± {elapsed/60:.1f}m â€¢ ETA {eta/60:.1f}m")

            with logs:
                st.write(f"ğŸŸ¦ Batch procesado â†’ filas hasta: {min(i+batch_size,total)}")

        status.success("ğŸ‰ ClasificaciÃ³n y generaciÃ³n de chistes completadas")

    except Exception as e:
        st.error(f"âŒ Error: {e}")
        st.warning("Se guardÃ³ el progreso parcial en progress_partial.csv")

    # ==========================================
    # ğŸ“ˆ DISTRIBUCIÃ“N DE TEMAS
    # ==========================================
    st.subheader("ğŸ“ˆ DistribuciÃ³n de temas")
    if "topic" in df.columns and df["topic"].notna().any():
        fig, ax = plt.subplots(figsize=(10,6))
        sns.countplot(
            data=df[df["topic"].notna()],
            y="topic",
            order=df["topic"].value_counts().index,
            ax=ax
        )
        st.pyplot(fig)
    else:
        st.info("AÃºn no hay temas suficientes para graficar.")

    # ==========================================
    # ğŸ¤ SECCIÃ“N E: â€œSTAND-UPâ€ POR TEMA
    # ==========================================
    st.subheader("ğŸ¤ Stand-up por tema")

    if "topic" in df.columns and "joke" in df.columns and df["topic"].notna().any():
        available_topics = sorted(df["topic"].dropna().unique().tolist())
        selected_topic = st.selectbox("Elige un tema para ver los chistes:", available_topics)

        n_show = st.slider("Â¿CuÃ¡ntos chistes quieres ver?", min_value=3, max_value=50, value=10, step=1)

        topic_df = df[(df["topic"] == selected_topic) & df["joke"].notna()]

        if len(topic_df) == 0:
            st.info("No hay chistes generados para este tema todavÃ­a.")
        else:
            # mezclar para que no siempre sean los mismos
            topic_sample = topic_df.sample(min(n_show, len(topic_df)))

            st.markdown(f"### ğŸ­ Chistes del tema: **{selected_topic}**")
            for idx, row in topic_sample.iterrows():
                original = row.get("text_clean", "")
                joke = row.get("joke", "")
                st.markdown(
                    f"""
                    <div style="border-radius:10px; padding:10px 15px; margin-bottom:8px; background-color:#1F2933;">
                        <div style="color:#9CA3AF; font-size:12px; margin-bottom:4px;">
                            ğŸ“ <b>Texto original:</b> {original}
                        </div>
                        <div style="color:#F9FAFB; font-size:14px;">
                            ğŸ˜‚ <b>Chiste:</b> {joke}
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
    else:
        st.info("Primero hay que terminar la clasificaciÃ³n y generaciÃ³n de chistes para ver esta secciÃ³n.")

    # ==========================================
    # ğŸ“¥ DESCARGA FINAL
    # ==========================================
    st.subheader("ğŸ“¦ Descargar resultados finales")
    st.download_button(
        "ğŸ“¥ Descargar CSV con temas y chistes",
        df.to_csv(index=False).encode("utf-8"),
        "classified_humor_with_jokes.csv"
    )
